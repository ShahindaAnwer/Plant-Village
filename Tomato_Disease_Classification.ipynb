{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luEd5iSPrNF2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Qe9Zo5wYjNyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Analysis**"
      ],
      "metadata": {
        "id": "AlAt6l37WImG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/ds/PlantVilage/Tomato\",\n",
        "    seed=123,\n",
        "    shuffle=True,\n",
        "    image_size = (256,256),\n",
        "    batch_size = 32\n",
        "    )"
      ],
      "metadata": {
        "id": "c97jyy1TVsWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dataset.class_names\n",
        "classes"
      ],
      "metadata": {
        "id": "z9Q36KzQKzpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('we have', len(dataset), 'batches')"
      ],
      "metadata": {
        "id": "-A2qVnGRLXHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in dataset.take(1):\n",
        "  print(image.shape, ':a batch of 32 elements of images of size (256, 256), and 3 for RGB channels')\n",
        "  print(label.numpy(), ':a batch of 32 elements of class labels, each is one of 5 classes')"
      ],
      "metadata": {
        "id": "Lp_mz018LZkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization**"
      ],
      "metadata": {
        "id": "YqFlP1UbPb21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(15):\n",
        "  ax = plt.subplot(3, 5, i + 1)\n",
        "  plt.imshow(image[i].numpy().astype(\"uint8\"))\n",
        "  plt.title(classes[label[i]])\n",
        "  plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "dN23lFerNHwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**data Splitting**"
      ],
      "metadata": {
        "id": "Rx5allqKPisj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    ds_size = len(ds)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "PXzhj6EIQ1Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "UlZv8H8FRWVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds), len(test_ds), len(val_ds))"
      ],
      "metadata": {
        "id": "vKPlhBaQRWsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "CeD4ikG8TBbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the image pixel value (0-1 by dividing by 256)\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(256,256),\n",
        "  layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "  ])"
      ],
      "metadata": {
        "id": "S6QqEk5LSpzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "Wds9n7Y9UTcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Creation**"
      ],
      "metadata": {
        "id": "zBTlngx9XEku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "model = Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = (256,256)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build(input_shape = (32,256,256,3))"
      ],
      "metadata": {
        "id": "UTJFLz0_W8hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "zpOvDJkmY9SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "FVA0cgo0aL5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=32,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        ")"
      ],
      "metadata": {
        "id": "qVYIFeKugM6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_ds)\n",
        "score"
      ],
      "metadata": {
        "id": "S7-S5PFJgf34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = m.history['accuracy']\n",
        "val_accuracy = m.history['val_accuracy']\n",
        "\n",
        "loss = m.history['loss']\n",
        "val_loss = m.history['val_loss']"
      ],
      "metadata": {
        "id": "jQGT7tb7aJu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(30), accuracy, label='Training Accuracy')\n",
        "plt.plot(range(30), val_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "e-osf75dbPBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(30), loss, label='Training Loss')\n",
        "plt.plot(range(30), val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "powUXOPTcBHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "6wD4fI82ipVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# use only 1 batch of 32 images\n",
        "for image, label in test_ds.take(1): \n",
        "  plt.imshow(image[0].numpy().astype('uint8'))\n",
        "  print('Actual Label =' ,classes[label[0]])\n",
        "\n",
        "  pred = model.predict(image)\n",
        "  print('Predicted Label = ', classes[np.argmax(pred[0])])"
      ],
      "metadata": {
        "id": "T3i5zF8dfO28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in test_ds.take(1): \n",
        "  plt.imshow(image[8].numpy().astype('uint8'))\n",
        "  print('Actual Label =' ,classes[label[8]])\n",
        "\n",
        "  pred = model.predict(image)\n",
        "  print('Predicted Label = ', classes[np.argmax(pred[8])])"
      ],
      "metadata": {
        "id": "tR2eFa1hkNKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in test_ds.take(1): \n",
        "  plt.imshow(image[11].numpy().astype('uint8'))\n",
        "  print('Actual Label =' ,classes[label[11]])\n",
        "\n",
        "  pred = model.predict(image)\n",
        "  print('Predicted Label = ', classes[np.argmax(pred[11])])"
      ],
      "metadata": {
        "id": "HZ1mOxP9nGzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct Predictions ✔✔✔"
      ],
      "metadata": {
        "id": "lSsIpbOnnTT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array, 0) # create a batch\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    predicted_class = classes[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence"
      ],
      "metadata": {
        "id": "-KQSE2xqnLem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        \n",
        "        predicted_class, confidence = predict(model, images[i].numpy())\n",
        "        actual_class = classes[labels[i]] \n",
        "        \n",
        "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
        "        \n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "q8Ix2pOgqnBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}